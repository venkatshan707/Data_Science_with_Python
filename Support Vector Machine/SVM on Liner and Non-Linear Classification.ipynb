{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clssification using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Suppose you are given plot of two label classes on graph as shown in image (A). Can you decide a separating line for the classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image](https://www.linkpicture.com/q/SVM1.png)](https://www.linkpicture.com/view.php?img=LPic62fa32c51e305162112667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have come up with something similar to following image (image B). It fairly separates the two classes. Any point that is left of line falls into black circle class and on right falls into blue square class. Separation of classes. That’s what SVM does. It finds out a line/ hyper-plane (in multidimensional space that separate outs classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image](https://www.linkpicture.com/q/SVM2.png)](https://www.linkpicture.com/view.php?img=LPic62fa32c51e305162112667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making it a Bit complex…\n",
    "-------------------------\n",
    "So far so good. Now consider what if we had data as shown in image below? Clearly, there is no line that can separate the two classes in this x-y plane. So what do we do? We apply transformation and add one more dimension as we call it z-axis. Lets assume value of points on z plane, w = x² + y². In this case we can manipulate it as distance of point from z-origin. \n",
    "\n",
    "Now if we plot in z-axis, a clear separation is visible \n",
    "and a line can be drawn ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image](https://www.linkpicture.com/q/SVM3.png)](https://www.linkpicture.com/view.php?img=LPic62fa32c51e305162112667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![image](https://www.linkpicture.com/q/SVM4.png)](https://www.linkpicture.com/view.php?img=LPic62fa32c51e305162112667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we transform back this line to original plane, it maps to circular boundary as shown in image E. These transformations are called kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image](https://www.linkpicture.com/q/SVM5.png)](https://www.linkpicture.com/view.php?img=LPic62fa32c51e305162112667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making it a little more complex…\n",
    "-----------------------------------------------\n",
    "\n",
    "What if data plot overlaps? \n",
    "Or, \n",
    "what in case some of the black points are inside the blue ones? \n",
    "Which line among 1 or 2 ? should we draw ?\n",
    "\n",
    "[![image](https://www.linkpicture.com/q/SVM6.png)](https://www.linkpicture.com/view.php?img=LPic62fa348765b821502125874)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called regularization parameter. \n",
    "\n",
    "* In next section, we define two terms regularization parameter and gamma. \n",
    "\n",
    "** These are tuning parameters in SVM classifier. Varying those we can achive considerable non linear classification line with more accuracy in reasonable amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning parameters: Regularization, Gamma and Margin.\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Regularization :\n",
    "---------------------\n",
    "The Regularization parameter (often termed as C parameter in python’s sklearn library) tells the SVM optimization how much you want to avoid misclassifying each training example.\n",
    "\n",
    "For large values of C(right diagram), the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C(left diagram) will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points.\n",
    "\n",
    "The images below are example of two different regularization parameter. \n",
    "**Left one has some misclassification due to lower regularization value. \n",
    "**Higher value leads to results like right one.\n",
    "\n",
    "GOOGLE SAYS \"LIFE AND HAPPINESS\" IS THE MOST CRITICAL DATA. IF ANY THING OTHER THAN THAT COMES, WE CAN GO FOR LEFT DIAGRAM, ELSE WE SHOULD CUMPOLSORILY GO FOR RIGHT DIAGRAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image](https://www.linkpicture.com/q/SVM7.png)](https://www.linkpicture.com/view.php?img=LPic62fa364fe1fa1389015983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma\n",
    "-----------\n",
    "The gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. In other words, with low gamma, points far away from plausible seperation line are considered in calculation for the seperation line. Where as high gamma means the points close to plausible line are considered in calculation.\n",
    "\n",
    "IF YOU HAVE TOO MUCH CONCENTRATION IN THE DATA, YOU USE HIGH GAMMA. EG: AVG MARKS OF 100 ARE MORE SATURATED IN REGION 50-75.\n",
    "\n",
    "IF YOU HAVE WELL DISTRIBUTED DATA(GAUSSIAN DISTRIBUTION), YOU USE LOW GAMMA. EG: AVG MARKS OF 100 ARE WELL DISTRIBUTED FROM 0 TO 100\n",
    "\n",
    "[![image](https://www.linkpicture.com/q/SVM8.png)](https://www.linkpicture.com/view.php?img=LPic62fa364fe1fa1389015983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin\n",
    "----------\n",
    "\n",
    "A margin is a separation of line to the closest class points.\n",
    "\n",
    "A good margin is one where this separation is larger for both the classes. Images below gives to visual example of good and bad margin. A good margin allows the points to be in their respective classes without crossing to other class.\n",
    "\n",
    "INCASE OF BAD MARGIN, THE POINT WHICH IS VERY CLOSE TO THE MARGIN WILL GET UP MISCLASSIFIED WHEN THE NEW DATA COMES IN.\n",
    "\n",
    "[![image](https://www.linkpicture.com/q/SVM9.png)](https://www.linkpicture.com/view.php?img=LPic62fa379877673194483145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on Linear Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ingledarshan/BK_Birla/main/bill_authentication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bill_authentication.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
